{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm to optimize investment in the stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign problem hyperparameters\n",
    "\n",
    "Two types of hyperparameters exist:\n",
    " - **Fixed parameters:** defined in the project statement\n",
    " - **Test parameters:** defined by us to test different implementations of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED PARAMETERS\n",
    "POPULATION_SIZE = 64 # number of individuals in population\n",
    "GENERATIONS = 10000   # number of generations\n",
    "EVALUATIONS = 10000   # number of evaluations\n",
    "MAX_RUNS = 30 # number of runs with different random seeds\n",
    "\n",
    "# TEST PARAMETERS\n",
    "CROSSOVER_PROBABILITY = 0.8 # probability of crossover operation\n",
    "MUTATION_PROBABILITY = 0.1 # probability of mutation operation\n",
    "TOURNAMENT_SIZE = 5 # number of individuals participating in tournament selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process datasets\n",
    "\n",
    "Filter the data relevant for the problem in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    # only relevant from 01/01/2020 onwards to 31/12/2022 (3 years)\n",
    "    # convert to datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "    data = data[data['Date'] >= '01-01-2011']\n",
    "    data = data[data['Date'] <= '31-12-2019']\n",
    "\n",
    "    # calculate the difference between consecutive values in the 'Close' column\n",
    "    value_diff = data['Close'].diff()\n",
    "\n",
    "    # create 'Gain' and 'Loss' columns based on the 'Value_Diff'\n",
    "    gain = value_diff.apply(lambda x: max(0, x))\n",
    "    loss = value_diff.apply(lambda x: max(0, -x))\n",
    "\n",
    "    # calculate the rolling sum of 'Gain' and 'Loss' for a 7-day, 14-day, and 21-day periods\n",
    "    average_gain_7 =  gain.rolling(window=7).mean()\n",
    "    average_loss_7 =  loss.rolling(window=7).mean()\n",
    "    average_gain_14 = gain.rolling(window=14).mean()\n",
    "    average_loss_14 = loss.rolling(window=14).mean()\n",
    "    average_gain_21 = gain.rolling(window=21).mean()\n",
    "    average_loss_21 = loss.rolling(window=21).mean()\n",
    "\n",
    "    # calculate the Relative Strength (RS)\n",
    "    rs_7 = average_gain_7/average_loss_7\n",
    "    rs_14 = average_gain_14/average_loss_14\n",
    "    rs_21 = average_gain_21/average_loss_21\n",
    "\n",
    "    # calculate the Relative Strength Index (RSI)\n",
    "    data['RSI7'] = 100 - (100/(1+rs_7))\n",
    "    data['RSI14'] = 100 - (100/(1+rs_14))\n",
    "    data['RSI21'] = 100 - (100/(1+rs_21))\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the fitness function\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# define the parameters\n",
    "rsi_periods = [7, 14, 21]\n",
    "lower_range = list(range(0, 101, 5))\n",
    "upper_range = list(range(0, 101, 5))\n",
    "\n",
    "# create the toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"rsi_period\", random.choice, rsi_periods)\n",
    "toolbox.register(\"bound\", random.choice, lower_range)\n",
    "\n",
    "toolbox.register(\"attr_pool\", tools.initCycle, tuple, [toolbox.rsi_period,\n",
    "                                                       toolbox.bound,\n",
    "                                                       toolbox.bound])\n",
    "\n",
    "tools.initCycle\n",
    "tools.initRepeat\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_pool, n=2)\n",
    "toolbox.register(\"population\",tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simulation function\n",
    "\n",
    "The simulation will be used in the **epigenesis** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_behaviour(individual, data):\n",
    "    # extract the parameters from the individual chromosome\n",
    "    (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "    \n",
    "    rsi_period_long = \"RSI\" + str(rsi_period_long)\n",
    "    rsi_period_short = \"RSI\" + str(rsi_period_short)\n",
    "\n",
    "    # based on the parameters, choose dates to buy and sell\n",
    "    long_buys = data[(data[rsi_period_long] >= lower_long) & \n",
    "                              ((data[rsi_period_long].shift(1) < lower_long) |\n",
    "                               (data[rsi_period_long].shift(1) == np.nan))].copy()\n",
    "    \n",
    "    short_sells = data[(data[rsi_period_short] <= upper_short) &\n",
    "                                ((data[rsi_period_short].shift(1) > upper_short) |\n",
    "                                 (data[rsi_period_short].shift(1) == np.nan))].copy()\n",
    "    \n",
    "    long_sells = []\n",
    "    # check for each long buy the next long sell\n",
    "    for index, row in long_buys.iterrows():\n",
    "        candidate_sells = data[(data['Date'] > row['Date']) &\n",
    "                               (data[rsi_period_long] >= upper_long)]\n",
    "        if (candidate_sells.empty):\n",
    "            new_sell = dict(data.iloc[-1])\n",
    "            new_sell['index'] = len(data) - 1\n",
    "        else:\n",
    "            new_sell = dict(candidate_sells.iloc[0])\n",
    "            new_sell['index'] = candidate_sells.index[0]\n",
    "        long_sells.append(new_sell)\n",
    "        drop_rows = [i for i in long_buys.index if i > index and i < new_sell['index']]\n",
    "        long_buys.drop(drop_rows, inplace=True) \n",
    "\n",
    "    # check for each short sell the next short buy\n",
    "    short_buys = []\n",
    "    for index, row in short_sells.iterrows():\n",
    "        candidate_buys = data[(data['Date'] > row['Date']) &\n",
    "                              (data[rsi_period_short] <= lower_short)]\n",
    "        if (candidate_buys.empty):\n",
    "            new_buy = dict(data.iloc[-1])\n",
    "            new_buy['index'] = len(data) - 1\n",
    "        else:\n",
    "            new_buy = dict(candidate_buys.iloc[0])\n",
    "            new_buy['index'] = candidate_buys.index[0]\n",
    "\n",
    "        short_buys.append(new_buy)\n",
    "        drop_rows = [i for i in short_sells.index if i > index and i < new_buy['index']]\n",
    "        short_sells.drop(drop_rows, inplace=True)\n",
    "\n",
    "\n",
    "    long_sells = pd.DataFrame(long_sells)\n",
    "    short_buys = pd.DataFrame(short_buys)\n",
    "\n",
    "    # remove duplcates \n",
    "    if not long_sells.empty:\n",
    "        long_sells.drop_duplicates(subset='index', inplace=True)\n",
    "        long_sells.set_index('index', inplace=True)\n",
    "    else:\n",
    "        long_sells = pd.DataFrame(columns=data.columns)\n",
    "    # remove duplicates\n",
    "    if not short_buys.empty:\n",
    "        short_buys.drop_duplicates(subset='index', inplace=True)\n",
    "        short_buys.set_index('index', inplace=True)\n",
    "    else:\n",
    "        short_buys = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    # merge buys and sells (buy long, sell long), (sell short, buy short)\n",
    "    trades_long = pd.merge_asof(long_buys, long_sells, \n",
    "                                left_index=True, right_index=True, \n",
    "                                direction='forward', suffixes=('_buy', '_sell'))\n",
    "    \n",
    "    trades_short = pd.merge_asof(short_sells, short_buys,\n",
    "                                 left_index=True, right_index=True,\n",
    "                                 direction='forward', suffixes=('_sell', '_buy'))\n",
    "\n",
    "    return (trades_long, trades_short)\n",
    "\n",
    "# trades_long, trades_short = simulate_behaviour(individual, data)\n",
    "\n",
    "# # plot evolution of RSI and points where buys and sells are possible\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(data['Date'], data['Close'], label='Close')\n",
    "# plt.plot(trades_long['Date_buy'], trades_long['Close_buy'], 'ro', label='Buys Long')\n",
    "# plt.plot(trades_long['Date_sell'], trades_long['Close_sell'], 'go', label='Sells Long')\n",
    "# plt.plot(trades_short['Date_sell'], trades_short['Close_sell'], 'bo', label='Sells Short')\n",
    "# plt.plot(trades_short['Date_buy'], trades_short['Close_buy'], 'yo', label='Buys Short')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "toolbox.register(\"simulate\", simulate_behaviour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define objective function\n",
    "\n",
    "The objective function will be used in the **selection** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(trades_long, trades_short):\n",
    "    # calculate the return on investment (ROI) for each trade\n",
    "    trades_long['ROI'] = (trades_long['Close_sell'] - trades_long['Close_buy']) / trades_long['Close_buy'] * 100\n",
    "    trades_short['ROI'] = (trades_short['Close_sell'] - trades_short['Close_buy']) / trades_short['Close_sell'] * 100\n",
    "\n",
    "    # calculate the total ROI for each trade type\n",
    "    average_roi_long = trades_long['ROI'].sum()\n",
    "    average_roi_short = trades_short['ROI'].sum()\n",
    "\n",
    "    # calculate the average ROI \n",
    "    average_roi = (average_roi_long + average_roi_short) / 2\n",
    "    return average_roi,\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define selection method\n",
    "\n",
    "The selection function will be used in the **survival** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define crossover method\n",
    "\n",
    "The crossover function will be used in the **crossover** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crossover Hyperparameters\n",
    "UNIFORM_PROBABILITY = 0.5\n",
    "AVERAGE_PROBABILITY = 0.5\n",
    "\n",
    "def crossover(individual1, individual2, method=\"one-point\"):\n",
    "    if method == \"one-point\":\n",
    "        # 1-point crossover\n",
    "        crossover_point = random.randint(0, len(individual1[0]) - 1)\n",
    "        child1 = individual1[:crossover_point] + individual2[crossover_point:]\n",
    "        child2 = individual2[:crossover_point] + individual1[crossover_point:]\n",
    "        return child1, child2\n",
    "    elif method == \"two-point\":\n",
    "        # 2-point crossover\n",
    "        crossover_point1 = random.randint(0, len(individual1[0]) - 1)\n",
    "        crossover_point2 = random.randint(crossover_point1, len(individual1[0]) - 1)\n",
    "        child1 = individual1[:crossover_point1] + individual2[crossover_point1:crossover_point2] + individual1[crossover_point2:]\n",
    "        child2 = individual2[:crossover_point1] + individual1[crossover_point1:crossover_point2] + individual2[crossover_point2:]\n",
    "        return child1, child2\n",
    "    elif method == \"uniform\":\n",
    "        # uniform crossover\n",
    "        child1 = individual1.copy()\n",
    "        child2 = individual2.copy()\n",
    "        for i in range(len(individual1)):\n",
    "            if random.random() < UNIFORM_PROBABILITY:\n",
    "                child1[i], child2[i] = individual2[i], individual1[i]\n",
    "        return child1, child2\n",
    "    elif method == \"average\":\n",
    "        # average crossover\n",
    "        if random.random() < AVERAGE_PROBABILITY:\n",
    "            child1 = (individual1+individual2)/2\n",
    "        return child1, child2\n",
    "    \n",
    "\n",
    "toolbox.register(\"mate\", crossover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define mutation method\n",
    "\n",
    "The mutation function will be used in the **mutation** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian mutation hyperparameters\n",
    "SIGMA = [0, 20, 20, 0, 20, 20]\n",
    "MU = 0\n",
    "GAUSSIAN_PROBABILITY = 0.7\n",
    "\n",
    "def mutationGaussian(individual):\n",
    "        (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            lower_short = np.random.normal(MU, SIGMA[1])\n",
    "            lower_short = max(0, min(100, lower_short))\n",
    "            lower_short = lower_short - (lower_short % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            upper_short = np.random.normal(MU, SIGMA[2])\n",
    "            upper_short = max(0, min(100, upper_short))\n",
    "            upper_short = upper_short - (upper_short % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            lower_long = np.random.normal(MU, SIGMA[4])\n",
    "            lower_long = max(0, min(100, lower_long))\n",
    "            lower_long = lower_long - (lower_long % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            upper_long = np.random.normal(MU, SIGMA[5])\n",
    "            upper_long = max(0, min(100, upper_long))\n",
    "            upper_long = upper_long - (upper_long % 5)\n",
    "\n",
    "        individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "        return individual,\n",
    "    \n",
    "# Single mutation hyperparameters\n",
    "MUTATION_BOUND = 10 # mutation bound - hyperparameter\n",
    "MUTATION_WINDOW = 7 # windows bound mutation - hyperparameter\n",
    "MUTATION_SINGLE_PROBABILITY = 0.5 # probability of single mutation - hyperparameter\n",
    "\n",
    "def mutationSingle(individual):\n",
    "        # mutation direction is either -1 (decrease) or 1 (increase)\n",
    "        (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "        mutation_direction = random.choice([-1, 1])\n",
    "        # mutate the parameter, consideration of bounds\n",
    "        if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            rsi_period_short = max(7, min(21, rsi_period_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            lower_short = max(0, min(100, lower_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            upper_short = max(0, min(100, upper_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            rsi_period_long = max(7, min(21, rsi_period_long + mutation_direction *  MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            lower_long = max(0, min(100, lower_long + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            upper_long = max(0, min(100, upper_long + mutation_direction * MUTATION_BOUND))\n",
    "        individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "        return individual,\n",
    "\n",
    "def mutationInversion(individual):\n",
    "    (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        rsi_period_short = 7 + 21 - rsi_period_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        rsi_period_long = 7 + 21 - rsi_period_long\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        lower_short = 100 - lower_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        upper_short = 100 - upper_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        lower_long = 100 - lower_long\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        upper_long = 100 - upper_long\n",
    "    individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "    return individual,\n",
    "\n",
    "def mutate(individual, method=\"single\"):\n",
    "    if method == \"single\":\n",
    "        mutant = mutationSingle(individual) # single mutation\n",
    "    elif method == \"gaussian\":\n",
    "        mutant = mutationGaussian(individual)\n",
    "    elif method == \"inversion\":\n",
    "        mutant = mutationInversion(individual)\n",
    "        return mutant,\n",
    "\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=100, indpb=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(data):\n",
    "    \n",
    "    pass\n",
    "\n",
    "def boxplot(data):\n",
    "    normalized_data = normalize(data)\n",
    "    for i in range(len(normalized_data)):\n",
    "        plt.boxplot(normalized_data[i])\n",
    "        plt.show()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Run: 0--\n",
      "\n",
      "[[(14, 65, 5), (14, 80, 75)], [(14, 45, 75), (14, 90, 30)], [(21, 20, 45), (7, 15, 95)], [(14, 85, 95), (7, 45, 15)], [(21, 10, 50), (14, 85, 15)], [(14, 65, 50), (21, 100, 30)], [(21, 75, 70), (21, 40, 5)], [(21, 0, 10), (21, 60, 100)], [(7, 95, 75), (14, 35, 50)], [(21, 10, 30), (21, 35, 35)], [(7, 85, 70), (7, 10, 50)], [(21, 75, 15), (14, 85, 45)], [(21, 15, 85), (14, 85, 30)], [(21, 85, 90), (14, 70, 10)], [(21, 60, 50), (21, 35, 45)], [(7, 30, 25), (7, 95, 40)], [(14, 10, 10), (21, 20, 20)], [(7, 10, 85), (21, 60, 80)], [(14, 80, 35), (7, 90, 65)], [(21, 40, 70), (14, 100, 55)], [(7, 50, 95), (7, 75, 90)], [(21, 50, 30), (7, 0, 40)], [(7, 35, 55), (7, 50, 65)], [(7, 15, 20), (21, 35, 5)], [(21, 100, 85), (21, 10, 0)], [(7, 100, 30), (21, 90, 15)], [(14, 10, 55), (7, 5, 95)], [(7, 30, 25), (21, 15, 75)], [(7, 5, 0), (21, 65, 95)], [(7, 40, 10), (7, 10, 100)], [(14, 55, 65), (7, 5, 80)], [(14, 5, 95), (7, 60, 30)], [(14, 55, 75), (21, 25, 30)], [(7, 25, 25), (14, 80, 40)], [(7, 95, 70), (21, 25, 0)], [(14, 65, 90), (21, 45, 100)], [(14, 60, 40), (7, 85, 0)], [(14, 10, 50), (21, 5, 85)], [(14, 20, 35), (14, 55, 95)], [(14, 55, 90), (21, 95, 20)], [(21, 45, 60), (21, 65, 100)], [(7, 0, 95), (7, 50, 25)], [(7, 35, 100), (14, 60, 90)], [(14, 5, 60), (21, 90, 65)], [(21, 5, 25), (14, 10, 40)], [(21, 25, 70), (21, 75, 85)], [(21, 0, 5), (14, 50, 45)], [(14, 5, 65), (7, 85, 100)], [(7, 20, 0), (14, 65, 50)], [(7, 30, 0), (21, 0, 80)], [(21, 15, 30), (7, 95, 100)], [(7, 45, 40), (21, 25, 15)], [(14, 60, 100), (7, 0, 40)], [(14, 15, 40), (7, 100, 80)], [(21, 100, 55), (7, 20, 40)], [(7, 5, 5), (7, 40, 85)], [(14, 55, 90), (7, 95, 100)], [(14, 100, 70), (21, 65, 55)], [(21, 25, 30), (14, 90, 45)], [(7, 20, 20), (14, 50, 50)], [(14, 10, 50), (21, 5, 5)], [(14, 25, 20), (21, 45, 55)], [(14, 85, 20), (14, 15, 75)], [(21, 35, 5), (14, 25, 80)]]\n",
      "Starting evolution...\n",
      "Evaluated 64 individuals\n",
      "--Generation: 0--\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15623/1243659853.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mlist_of_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mconvergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m# maximum number of generations without improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mstd_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m \u001b[0;31m# threshold for standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15623/1243659853.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# evaluate the individuals with an invalid fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moffspring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbehaviours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mbhv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbhv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbehaviours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mevaluations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluated {0} individuals'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15623/1243659853.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(ind)\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mbehaviours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15623/1411604412.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(individual, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlong_buys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# check for each short sell the next short buy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mshort_buys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshort_sells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         candidate_buys = data[(data['Date'] > row['Date']) &\n\u001b[1;32m     36\u001b[0m                               (data[rsi_period_short] <= lower_short)]\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidate_buys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0musing_cow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musing_cow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_single_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def algorithm(data):\n",
    "    list_of_output = []\n",
    "    convergence = 3 # maximum number of generations without improvement\n",
    "    std_threshold = 1e-4 # threshold for standard deviation\n",
    "    \n",
    "    for i in range(MAX_RUNS):\n",
    "        count = 0 # counter for convergence\n",
    "        random.seed(i) # set random seed for each run\n",
    "        print('--Run: {0}--\\n'.format(i))\n",
    "        evaluations = 0\n",
    "        # create the initial population\n",
    "        pop = toolbox.population(n=POPULATION_SIZE)\n",
    "        print(pop)\n",
    "        \n",
    "        print('Starting evolution...')\n",
    "\n",
    "        # evaluate the entire population\n",
    "        behaviours = list(map(lambda ind: toolbox.simulate(ind, data), pop))\n",
    "        fitnesses = list(map(lambda bhv: toolbox.evaluate(bhv[0], bhv[1]), behaviours)) \n",
    "        evaluations += len(pop)\n",
    "        \n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        print('Evaluated {0} individuals'.format(len(pop)))\n",
    "\n",
    "        for g in range(GENERATIONS):\n",
    "            print('--Generation: {0}--'.format(g))\n",
    "            # select the next generation individuals\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            # clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "            # apply crossover and mutation on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < CROSSOVER_PROBABILITY:\n",
    "                    toolbox.mate(child1, child2, 'two-point')\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "            for mutant in offspring:\n",
    "                if random.random() < MUTATION_PROBABILITY:\n",
    "                    toolbox.mutate(mutant, 'inversion')\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            behaviours = map(lambda ind: toolbox.simulate(ind, data), invalid_ind)\n",
    "            fitnesses = map(lambda bhv: toolbox.evaluate(bhv[0], bhv[1]), behaviours)\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "            evaluations += len(invalid_ind)\n",
    "            print('Evaluated {0} individuals'.format(len(invalid_ind)))\n",
    "\n",
    "            pop[:] = offspring\n",
    "\n",
    "            fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "            length = len(pop)\n",
    "            mean = sum(fits) / length\n",
    "            sum2 = sum(x*x for x in fits)\n",
    "            std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "            print('Min: {0}'.format(min(fits)))\n",
    "            print('Max: {0}'.format(max(fits)))\n",
    "            print('Avg: {0}'.format(mean))\n",
    "            print('Std: {0}'.format(std))\n",
    "            print('Current evaluations : ', evaluations)\n",
    "            \n",
    "            dictionary = {\n",
    "                'DATASET': df_name,\n",
    "                'RUN': i,\n",
    "                'MIN': min(fits),\n",
    "                'MAX': max(fits),\n",
    "                'AVG': mean,\n",
    "                'STD': std,\n",
    "                'best_individual': pop[np.argmax(fits)]\n",
    "            }\n",
    "        \n",
    "            if (std<std_threshold):\n",
    "                count +=1\n",
    "            \n",
    "            if (count == convergence or evaluations > EVALUATIONS):\n",
    "                list_of_output.append(dictionary)\n",
    "                print('-- End of (successful) evolution --')\n",
    "                break\n",
    "    df = pd.DataFrame(list_of_output)       \n",
    "    df.to_csv('results.csv', mode='a', header=False, index=False)    \n",
    "\n",
    "    # obtain best individuals in each run for test scheme\n",
    "    best_individuals = df['best_individual'].tolist()\n",
    "    # save to csv\n",
    "    df = pd.DataFrame(best_individuals)\n",
    "    df.to_csv('best_individuals.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    # obtain averages of the runs and minimums, maximums, averages, and standard deviations of the best individuals\n",
    "    min_values = [item['MIN'] for item in list_of_output]\n",
    "    max_values = [item['MAX'] for item in list_of_output]\n",
    "    avg_values = [item['AVG'] for item in list_of_output]\n",
    "    std_values = [item['STD'] for item in list_of_output]\n",
    "    min_average = sum(min_values) / len(min_values)\n",
    "    max_average = sum(max_values) / len(max_values)\n",
    "    avg_average = sum(avg_values) / len(avg_values)\n",
    "    std_average = sum(std_values) / len(std_values)\n",
    "\n",
    "\n",
    "    min_from_output = min(list_of_output, key=lambda x:x['MIN'])\n",
    "    max_from_output = max(list_of_output, key=lambda x:x['MAX'])\n",
    "    avg_from_output = max(list_of_output, key=lambda x:x['AVG'])\n",
    "    std_from_output = min(list_of_output, key=lambda x:x['STD'])\n",
    "    dictionary_output = {\n",
    "        'DATASET': df_name,\n",
    "        'MIN': min_from_output['MIN'],\n",
    "        'MAX': max_from_output['MAX'],\n",
    "        'AVG': avg_from_output['AVG'],\n",
    "        'STD': std_from_output['STD'],\n",
    "        'AVG_MIN': min_average,\n",
    "        'AVG_MAX': max_average,\n",
    "        'AVG_AVG': avg_average,\n",
    "        'AVG_STD': std_average,\n",
    "    }\n",
    "    # save results for table in report\n",
    "    df2 = pd.DataFrame(dictionary_output, index=[0])\n",
    "    df2.to_csv('results_for_table.csv', mode='a', header=False, index=False)\n",
    "\n",
    "            \n",
    "folder_path = 'data'\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "data_dictionary = {}\n",
    "RSI_dictionary = {}\n",
    "price_dictionary = {}\n",
    "date_dictionary = {}\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.csv'):\n",
    "        # extract the base name of the file (without the extension)\n",
    "        df_name = os.path.splitext(file_name)[0]\n",
    "        # construct the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # read the CSV file into a DataFrame with the base name as the variable name\n",
    "        data_dictionary[df_name] = pd.read_csv(file_path, sep=';', usecols=['Date', 'Close'])\n",
    "        data = process_data(data_dictionary[df_name])\n",
    "        data_dictionary[df_name] = data\n",
    "\n",
    "for df_name in data_dictionary:\n",
    "    algorithm(data_dictionary[df_name])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
