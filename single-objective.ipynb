{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm to optimize investment in the stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign problem hyperparameters\n",
    "\n",
    "Two types of hyperparameters exist:\n",
    " - **Fixed parameters:** defined in the project statement\n",
    " - **Test parameters:** defined by us to test different implementations of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED PARAMETERS\n",
    "POPULATION_SIZE = 64 # number of individuals in population\n",
    "GENERATIONS = 10000   # number of generations\n",
    "EVALUATIONS = 10000   # number of evaluations\n",
    "MAX_RUNS = 30 # number of runs with different random seeds\n",
    "\n",
    "# TEST PARAMETERS\n",
    "CROSSOVER_PROBABILITY = 0.8 # probability of crossover operation\n",
    "MUTATION_PROBABILITY = 0.1 # probability of mutation operation\n",
    "TOURNAMENT_SIZE = 5 # number of individuals participating in tournament selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process datasets\n",
    "\n",
    "Filter the data relevant for the problem in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    # only relevant from 01/01/2020 onwards to 31/12/2022 (3 years)\n",
    "    # convert to datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "    data = data[data['Date'] >= '01-01-2020']\n",
    "    data = data[data['Date'] <= '31-12-2022']\n",
    "\n",
    "    # calculate the difference between consecutive values in the 'Close' column\n",
    "    value_diff = data['Close'].diff()\n",
    "\n",
    "    # create 'Gain' and 'Loss' columns based on the 'Value_Diff'\n",
    "    gain = value_diff.apply(lambda x: max(0, x))\n",
    "    loss = value_diff.apply(lambda x: max(0, -x))\n",
    "\n",
    "    # calculate the rolling sum of 'Gain' and 'Loss' for a 7-day, 14-day, and 21-day periods\n",
    "    average_gain_7 =  gain.rolling(window=7).mean()\n",
    "    average_loss_7 =  loss.rolling(window=7).mean()\n",
    "    average_gain_14 = gain.rolling(window=14).mean()\n",
    "    average_loss_14 = loss.rolling(window=14).mean()\n",
    "    average_gain_21 = gain.rolling(window=21).mean()\n",
    "    average_loss_21 = loss.rolling(window=21).mean()\n",
    "\n",
    "    # calculate the Relative Strength (RS)\n",
    "    rs_7 = average_gain_7/average_loss_7\n",
    "    rs_14 = average_gain_14/average_loss_14\n",
    "    rs_21 = average_gain_21/average_loss_21\n",
    "\n",
    "    # calculate the Relative Strength Index (RSI)\n",
    "    data['RSI7'] = 100 - (100/(1+rs_7))\n",
    "    data['RSI14'] = 100 - (100/(1+rs_14))\n",
    "    data['RSI21'] = 100 - (100/(1+rs_21))\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haohua/.local/lib/python3.8/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/haohua/.local/lib/python3.8/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# create the fitness function\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# define the parameters\n",
    "rsi_periods = [7, 14, 21]\n",
    "lower_range = list(range(0, 101, 5))\n",
    "upper_range = list(range(0, 101, 5))\n",
    "\n",
    "# create the toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"rsi_period\", random.choice, rsi_periods)\n",
    "toolbox.register(\"bound\", random.choice, lower_range)\n",
    "\n",
    "toolbox.register(\"attr_pool\", tools.initCycle, tuple, [toolbox.rsi_period,\n",
    "                                                       toolbox.bound,\n",
    "                                                       toolbox.bound])\n",
    "\n",
    "tools.initCycle\n",
    "tools.initRepeat\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_pool, n=2)\n",
    "toolbox.register(\"population\",tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define simulation function\n",
    "\n",
    "The simulation will be used in the **epigenesis** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_behaviour(individual, data):\n",
    "    # extract the parameters from the individual chromosome\n",
    "    (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "    \n",
    "    rsi_period_long = \"RSI\" + str(rsi_period_long)\n",
    "    rsi_period_short = \"RSI\" + str(rsi_period_short)\n",
    "\n",
    "    # based on the parameters, choose dates to buy and sell\n",
    "    long_buys = data[(data[rsi_period_long] >= lower_long) & \n",
    "                              ((data[rsi_period_long].shift(1) < lower_long) |\n",
    "                               (data[rsi_period_long].shift(1) == np.nan))].copy()\n",
    "    \n",
    "    short_sells = data[(data[rsi_period_short] <= upper_short) &\n",
    "                                ((data[rsi_period_short].shift(1) > upper_short) |\n",
    "                                 (data[rsi_period_short].shift(1) == np.nan))].copy()\n",
    "    \n",
    "    long_sells = []\n",
    "    # check for each long buy the next long sell\n",
    "    for index, row in long_buys.iterrows():\n",
    "        candidate_sells = data[(data['Date'] > row['Date']) &\n",
    "                               (data[rsi_period_long] >= upper_long)]\n",
    "        if (candidate_sells.empty):\n",
    "            new_sell = dict(data.iloc[-1])\n",
    "            new_sell['index'] = len(data) - 1\n",
    "        else:\n",
    "            new_sell = dict(candidate_sells.iloc[0])\n",
    "            new_sell['index'] = candidate_sells.index[0]\n",
    "        long_sells.append(new_sell)\n",
    "        drop_rows = [i for i in long_buys.index if i > index and i < new_sell['index']]\n",
    "        long_buys.drop(drop_rows, inplace=True) \n",
    "\n",
    "    # check for each short sell the next short buy\n",
    "    short_buys = []\n",
    "    for index, row in short_sells.iterrows():\n",
    "        candidate_buys = data[(data['Date'] > row['Date']) &\n",
    "                              (data[rsi_period_short] <= lower_short)]\n",
    "        if (candidate_buys.empty):\n",
    "            new_buy = dict(data.iloc[-1])\n",
    "            new_buy['index'] = len(data) - 1\n",
    "        else:\n",
    "            new_buy = dict(candidate_buys.iloc[0])\n",
    "            new_buy['index'] = candidate_buys.index[0]\n",
    "\n",
    "        short_buys.append(new_buy)\n",
    "        drop_rows = [i for i in short_sells.index if i > index and i < new_buy['index']]\n",
    "        short_sells.drop(drop_rows, inplace=True)\n",
    "\n",
    "\n",
    "    long_sells = pd.DataFrame(long_sells)\n",
    "    short_buys = pd.DataFrame(short_buys)\n",
    "\n",
    "    # remove duplcates \n",
    "    if not long_sells.empty:\n",
    "        long_sells.drop_duplicates(subset='index', inplace=True)\n",
    "        long_sells.set_index('index', inplace=True)\n",
    "    else:\n",
    "        long_sells = pd.DataFrame(columns=data.columns)\n",
    "    # remove duplicates\n",
    "    if not short_buys.empty:\n",
    "        short_buys.drop_duplicates(subset='index', inplace=True)\n",
    "        short_buys.set_index('index', inplace=True)\n",
    "    else:\n",
    "        short_buys = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    # merge buys and sells (buy long, sell long), (sell short, buy short)\n",
    "    trades_long = pd.merge_asof(long_buys, long_sells, \n",
    "                                left_index=True, right_index=True, \n",
    "                                direction='forward', suffixes=('_buy', '_sell'))\n",
    "    \n",
    "    trades_short = pd.merge_asof(short_sells, short_buys,\n",
    "                                 left_index=True, right_index=True,\n",
    "                                 direction='forward', suffixes=('_sell', '_buy'))\n",
    "\n",
    "    return (trades_long, trades_short)\n",
    "\n",
    "# trades_long, trades_short = simulate_behaviour(individual, data)\n",
    "\n",
    "# # plot evolution of RSI and points where buys and sells are possible\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(data['Date'], data['Close'], label='Close')\n",
    "# plt.plot(trades_long['Date_buy'], trades_long['Close_buy'], 'ro', label='Buys Long')\n",
    "# plt.plot(trades_long['Date_sell'], trades_long['Close_sell'], 'go', label='Sells Long')\n",
    "# plt.plot(trades_short['Date_sell'], trades_short['Close_sell'], 'bo', label='Sells Short')\n",
    "# plt.plot(trades_short['Date_buy'], trades_short['Close_buy'], 'yo', label='Buys Short')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "toolbox.register(\"simulate\", simulate_behaviour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define objective function\n",
    "\n",
    "The objective function will be used in the **selection** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(trades_long, trades_short):\n",
    "    # calculate the return on investment (ROI) for each trade\n",
    "    trades_long['ROI'] = (trades_long['Close_sell'] - trades_long['Close_buy']) / trades_long['Close_buy'] * 100\n",
    "    trades_short['ROI'] = (trades_short['Close_sell'] - trades_short['Close_buy']) / trades_short['Close_sell'] * 100\n",
    "\n",
    "    # calculate the total ROI for each trade type\n",
    "    average_roi_long = trades_long['ROI'].sum()\n",
    "    average_roi_short = trades_short['ROI'].sum()\n",
    "\n",
    "    # calculate the average ROI \n",
    "    average_roi = (average_roi_long + average_roi_short) / 2\n",
    "    return average_roi,\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define selection method\n",
    "\n",
    "The selection function will be used in the **survival** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define crossover method\n",
    "\n",
    "The crossover function will be used in the **crossover** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crossover Hyperparameters\n",
    "UNIFORM_PROBABILITY = 0.5\n",
    "AVERAGE_PROBABILITY = 0.5\n",
    "\n",
    "def crossover(individual1, individual2, method=\"one-point\"):\n",
    "    if method == \"one-point\":\n",
    "        # 1-point crossover\n",
    "        crossover_point = random.randint(0, len(individual1[0]) - 1)\n",
    "        child1 = individual1[:crossover_point] + individual2[crossover_point:]\n",
    "        child2 = individual2[:crossover_point] + individual1[crossover_point:]\n",
    "        return child1, child2\n",
    "    elif method == \"two-point\":\n",
    "        # 2-point crossover\n",
    "        crossover_point1 = random.randint(0, len(individual1[0]) - 1)\n",
    "        crossover_point2 = random.randint(crossover_point1, len(individual1[0]) - 1)\n",
    "        child1 = individual1[:crossover_point1] + individual2[crossover_point1:crossover_point2] + individual1[crossover_point2:]\n",
    "        child2 = individual2[:crossover_point1] + individual1[crossover_point1:crossover_point2] + individual2[crossover_point2:]\n",
    "        return child1, child2\n",
    "    elif method == \"uniform\":\n",
    "        # uniform crossover\n",
    "        child1 = individual1.copy()\n",
    "        child2 = individual2.copy()\n",
    "        for i in range(len(individual1)):\n",
    "            if random.random() < UNIFORM_PROBABILITY:\n",
    "                child1[i], child2[i] = individual2[i], individual1[i]\n",
    "        return child1, child2\n",
    "    elif method == \"average\":\n",
    "        # average crossover\n",
    "        if random.random() < AVERAGE_PROBABILITY:\n",
    "            child1 = (individual1+individual2)/2\n",
    "        return child1, child2\n",
    "    \n",
    "\n",
    "toolbox.register(\"mate\", crossover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define mutation method\n",
    "\n",
    "The mutation function will be used in the **mutation** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian mutation hyperparameters\n",
    "SIGMA = [0, 20, 20, 0, 20, 20]\n",
    "MU = 0\n",
    "GAUSSIAN_PROBABILITY = 0.7\n",
    "\n",
    "def mutationGaussian(individual):\n",
    "        (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            lower_short = np.random.normal(MU, SIGMA[1])\n",
    "            lower_short = max(0, min(100, lower_short))\n",
    "            lower_short = lower_short - (lower_short % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            upper_short = np.random.normal(MU, SIGMA[2])\n",
    "            upper_short = max(0, min(100, upper_short))\n",
    "            upper_short = upper_short - (upper_short % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            lower_long = np.random.normal(MU, SIGMA[4])\n",
    "            lower_long = max(0, min(100, lower_long))\n",
    "            lower_long = lower_long - (lower_long % 5)\n",
    "        if random.random()<GAUSSIAN_PROBABILITY:\n",
    "            upper_long = np.random.normal(MU, SIGMA[5])\n",
    "            upper_long = max(0, min(100, upper_long))\n",
    "            upper_long = upper_long - (upper_long % 5)\n",
    "\n",
    "        individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "        return individual,\n",
    "    \n",
    "# Single mutation hyperparameters\n",
    "MUTATION_BOUND = 10 # mutation bound - hyperparameter\n",
    "MUTATION_WINDOW = 7 # windows bound mutation - hyperparameter\n",
    "MUTATION_SINGLE_PROBABILITY = 0.5 # probability of single mutation - hyperparameter\n",
    "\n",
    "def mutationSingle(individual):\n",
    "        # mutation direction is either -1 (decrease) or 1 (increase)\n",
    "        (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "        mutation_direction = random.choice([-1, 1])\n",
    "        # mutate the parameter, consideration of bounds\n",
    "        if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            rsi_period_short = max(7, min(21, rsi_period_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            lower_short = max(0, min(100, lower_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            upper_short = max(0, min(100, upper_short + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            rsi_period_long = max(7, min(21, rsi_period_long + mutation_direction *  MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            lower_long = max(0, min(100, lower_long + mutation_direction * MUTATION_BOUND))\n",
    "        elif random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "            mutation_direction = random.choice([-1, 1])\n",
    "            upper_long = max(0, min(100, upper_long + mutation_direction * MUTATION_BOUND))\n",
    "        individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "        return individual,\n",
    "\n",
    "def mutationInversion(individual):\n",
    "    (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long) = individual\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        rsi_period_short = 7 + 21 - rsi_period_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        rsi_period_long = 7 + 21 - rsi_period_long\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        lower_short = 100 - lower_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        upper_short = 100 - upper_short\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        lower_long = 100 - lower_long\n",
    "    if random.random() < MUTATION_SINGLE_PROBABILITY:\n",
    "        upper_long = 100 - upper_long\n",
    "    individual = (rsi_period_short, lower_short, upper_short), (rsi_period_long, lower_long, upper_long)\n",
    "    return individual,\n",
    "\n",
    "def mutate(individual, method=\"single\"):\n",
    "    if method == \"single\":\n",
    "        mutant = mutationSingle(individual) # single mutation\n",
    "    elif method == \"gaussian\":\n",
    "        mutant = mutationGaussian(individual)\n",
    "    elif method == \"inversion\":\n",
    "        mutant = mutationInversion(individual)\n",
    "        return mutant,\n",
    "\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=100, indpb=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(data):\n",
    "    \n",
    "    pass\n",
    "\n",
    "def boxplot(data):\n",
    "    normalized_data = normalize(data)\n",
    "    for i in range(len(normalized_data)):\n",
    "        plt.boxplot(normalized_data[i])\n",
    "        plt.show()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Run: 0--\n",
      "\n",
      "[[(14, 65, 5), (14, 80, 75)], [(14, 45, 75), (14, 90, 30)], [(21, 20, 45), (7, 15, 95)], [(14, 85, 95), (7, 45, 15)], [(21, 10, 50), (14, 85, 15)], [(14, 65, 50), (21, 100, 30)], [(21, 75, 70), (21, 40, 5)], [(21, 0, 10), (21, 60, 100)], [(7, 95, 75), (14, 35, 50)], [(21, 10, 30), (21, 35, 35)], [(7, 85, 70), (7, 10, 50)], [(21, 75, 15), (14, 85, 45)], [(21, 15, 85), (14, 85, 30)], [(21, 85, 90), (14, 70, 10)], [(21, 60, 50), (21, 35, 45)], [(7, 30, 25), (7, 95, 40)], [(14, 10, 10), (21, 20, 20)], [(7, 10, 85), (21, 60, 80)], [(14, 80, 35), (7, 90, 65)], [(21, 40, 70), (14, 100, 55)], [(7, 50, 95), (7, 75, 90)], [(21, 50, 30), (7, 0, 40)], [(7, 35, 55), (7, 50, 65)], [(7, 15, 20), (21, 35, 5)], [(21, 100, 85), (21, 10, 0)], [(7, 100, 30), (21, 90, 15)], [(14, 10, 55), (7, 5, 95)], [(7, 30, 25), (21, 15, 75)], [(7, 5, 0), (21, 65, 95)], [(7, 40, 10), (7, 10, 100)], [(14, 55, 65), (7, 5, 80)], [(14, 5, 95), (7, 60, 30)], [(14, 55, 75), (21, 25, 30)], [(7, 25, 25), (14, 80, 40)], [(7, 95, 70), (21, 25, 0)], [(14, 65, 90), (21, 45, 100)], [(14, 60, 40), (7, 85, 0)], [(14, 10, 50), (21, 5, 85)], [(14, 20, 35), (14, 55, 95)], [(14, 55, 90), (21, 95, 20)], [(21, 45, 60), (21, 65, 100)], [(7, 0, 95), (7, 50, 25)], [(7, 35, 100), (14, 60, 90)], [(14, 5, 60), (21, 90, 65)], [(21, 5, 25), (14, 10, 40)], [(21, 25, 70), (21, 75, 85)], [(21, 0, 5), (14, 50, 45)], [(14, 5, 65), (7, 85, 100)], [(7, 20, 0), (14, 65, 50)], [(7, 30, 0), (21, 0, 80)], [(21, 15, 30), (7, 95, 100)], [(7, 45, 40), (21, 25, 15)], [(14, 60, 100), (7, 0, 40)], [(14, 15, 40), (7, 100, 80)], [(21, 100, 55), (7, 20, 40)], [(7, 5, 5), (7, 40, 85)], [(14, 55, 90), (7, 95, 100)], [(14, 100, 70), (21, 65, 55)], [(21, 25, 30), (14, 90, 45)], [(7, 20, 20), (14, 50, 50)], [(14, 10, 50), (21, 5, 5)], [(14, 25, 20), (21, 45, 55)], [(14, 85, 20), (14, 15, 75)], [(21, 35, 5), (14, 25, 80)]]\n",
      "Starting evolution...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb Cell 25\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         data_dictionary[df_name] \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mfor\u001b[39;00m df_name \u001b[39min\u001b[39;00m data_dictionary:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     algorithm(data_dictionary[df_name])\n",
      "\u001b[1;32m/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStarting evolution...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# evaluate the entire population\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m behaviours \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m ind: toolbox\u001b[39m.\u001b[39;49msimulate(ind, data), pop))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m fitnesses \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m bhv: toolbox\u001b[39m.\u001b[39mevaluate(bhv[\u001b[39m0\u001b[39m], bhv[\u001b[39m1\u001b[39m]), behaviours)) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m evaluations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pop)\n",
      "\u001b[1;32m/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStarting evolution...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# evaluate the entire population\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m behaviours \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m ind: toolbox\u001b[39m.\u001b[39;49msimulate(ind, data), pop))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m fitnesses \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m bhv: toolbox\u001b[39m.\u001b[39mevaluate(bhv[\u001b[39m0\u001b[39m], bhv[\u001b[39m1\u001b[39m]), behaviours)) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m evaluations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pop)\n",
      "\u001b[1;32m/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m long_sells\u001b[39m.\u001b[39mempty:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     long_sells\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     long_sells\u001b[39m.\u001b[39;49mset_index(\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haohua/Downloads/evolutionary-algorithms-for-stock-market-main/single-objective.ipynb#X33sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     long_sells \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:5923\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5921\u001b[0m \u001b[39m# use set to handle duplicate column names gracefully in case of drop\u001b[39;00m\n\u001b[1;32m   5922\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(to_remove):\n\u001b[0;32m-> 5923\u001b[0m     \u001b[39mdel\u001b[39;00m frame[c]\n\u001b[1;32m   5925\u001b[0m \u001b[39m# clear up memory usage\u001b[39;00m\n\u001b[1;32m   5926\u001b[0m index\u001b[39m.\u001b[39m_cleanup()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:4280\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deleted:\n\u001b[1;32m   4276\u001b[0m     \u001b[39m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[1;32m   4277\u001b[0m     \u001b[39m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[1;32m   4278\u001b[0m     \u001b[39m# exception:\u001b[39;00m\n\u001b[1;32m   4279\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m-> 4280\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49midelete(loc)\n\u001b[1;32m   4282\u001b[0m \u001b[39m# delete from the caches\u001b[39;00m\n\u001b[1;32m   4283\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py:1476\u001b[0m, in \u001b[0;36mBlockManager.idelete\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1473\u001b[0m is_deleted[indexer] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m taker \u001b[39m=\u001b[39m (\u001b[39m~\u001b[39mis_deleted)\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1476\u001b[0m nbs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_take_blocks_ax0(taker, only_slice\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1477\u001b[0m new_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems[\u001b[39m~\u001b[39mis_deleted]\n\u001b[1;32m   1478\u001b[0m axes \u001b[39m=\u001b[39m [new_columns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py:797\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39mSlice/take blocks along axis=0.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[39mnew_blocks : list of Block\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    795\u001b[0m allow_fill \u001b[39m=\u001b[39m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default\n\u001b[0;32m--> 797\u001b[0m sl_type, slobj, sllen \u001b[39m=\u001b[39m _preprocess_slice_or_indexer(\n\u001b[1;32m    798\u001b[0m     slice_or_indexer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], allow_fill\u001b[39m=\u001b[39;49mallow_fill\n\u001b[1;32m    799\u001b[0m )\n\u001b[1;32m    801\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_single_block:\n\u001b[1;32m    802\u001b[0m     blk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py:2342\u001b[0m, in \u001b[0;36m_preprocess_slice_or_indexer\u001b[0;34m(slice_or_indexer, length, allow_fill)\u001b[0m\n\u001b[1;32m   2340\u001b[0m indexer \u001b[39m=\u001b[39m ensure_platform_int(slice_or_indexer)\n\u001b[1;32m   2341\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_fill:\n\u001b[0;32m-> 2342\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, length)\n\u001b[1;32m   2343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfancy\u001b[39m\u001b[39m\"\u001b[39m, indexer, \u001b[39mlen\u001b[39m(indexer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexers/utils.py:276\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(indices) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    272\u001b[0m         \u001b[39m# If `indices` is empty, np.array will return a float,\u001b[39;00m\n\u001b[1;32m    273\u001b[0m         \u001b[39m# and will cause indexing errors.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m--> 276\u001b[0m mask \u001b[39m=\u001b[39m indices \u001b[39m<\u001b[39;49m \u001b[39m0\u001b[39;49m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m    278\u001b[0m     indices \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def algorithm(data):\n",
    "    for i in range(MAX_RUNS):\n",
    "        random.seed(i) # set random seed for each run\n",
    "        print('--Run: {0}--\\n'.format(i))\n",
    "        evaluations = 0\n",
    "        # create the initial population\n",
    "        pop = toolbox.population(n=POPULATION_SIZE)\n",
    "        print(pop)\n",
    "        print('Starting evolution...')\n",
    "\n",
    "        # evaluate the entire population\n",
    "        behaviours = list(map(lambda ind: toolbox.simulate(ind, data), pop))\n",
    "        fitnesses = list(map(lambda bhv: toolbox.evaluate(bhv[0], bhv[1]), behaviours)) \n",
    "        evaluations += len(pop)\n",
    "        \n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        print('Evaluated {0} individuals'.format(len(pop)))\n",
    "        for g in range(GENERATIONS):\n",
    "            print('--Generation: {0}--'.format(g))\n",
    "            # select the next generation individuals\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            # clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "            # apply crossover and mutation on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < CROSSOVER_PROBABILITY:\n",
    "                    toolbox.mate(child1, child2, 'two-point')\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "            for mutant in offspring:\n",
    "                if random.random() < MUTATION_PROBABILITY:\n",
    "                    toolbox.mutate(mutant, 'inversion')\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            behaviours = map(lambda ind: toolbox.simulate(ind, data), invalid_ind)\n",
    "            fitnesses = map(lambda bhv: toolbox.evaluate(bhv[0], bhv[1]), behaviours)\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "            evaluations += len(invalid_ind)\n",
    "            print('Evaluated {0} individuals'.format(len(invalid_ind)))\n",
    "\n",
    "            pop[:] = offspring\n",
    "\n",
    "            fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "            length = len(pop)\n",
    "            mean = sum(fits) / length\n",
    "            sum2 = sum(x*x for x in fits)\n",
    "            std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "            print('Min: {0}'.format(min(fits)))\n",
    "            print('Max: {0}'.format(max(fits)))\n",
    "            print('Avg: {0}'.format(mean))\n",
    "            print('Std: {0}'.format(std))\n",
    "            print('Current evaluations : ', evaluations)\n",
    "            \n",
    "            dictionary = {\n",
    "                'DATASET': df_name,\n",
    "                'RUN': i,\n",
    "                'MIN': min(fits),\n",
    "                'MAX': max(fits),\n",
    "                'AVG': mean,\n",
    "                'STD': std\n",
    "            }\n",
    "\n",
    "            if (evaluations >= EVALUATIONS or std<1e-4):\n",
    "                df = pd.DataFrame(dictionary, index=[0])\n",
    "                df.to_csv('results.csv', mode='a', header=False, index=False)\n",
    "                print('-- End of (successful) evolution --')\n",
    "                break       \n",
    "            \n",
    "folder_path = 'data'\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "data_dictionary = {}\n",
    "RSI_dictionary = {}\n",
    "price_dictionary = {}\n",
    "date_dictionary = {}\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.csv'):\n",
    "        # extract the base name of the file (without the extension)\n",
    "        df_name = os.path.splitext(file_name)[0]\n",
    "        # construct the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # read the CSV file into a DataFrame with the base name as the variable name\n",
    "        data_dictionary[df_name] = pd.read_csv(file_path, sep=';', usecols=['Date', 'Close'])\n",
    "        data = process_data(data_dictionary[df_name])\n",
    "        data_dictionary[df_name] = data\n",
    "\n",
    "for df_name in data_dictionary:\n",
    "    algorithm(data_dictionary[df_name])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
